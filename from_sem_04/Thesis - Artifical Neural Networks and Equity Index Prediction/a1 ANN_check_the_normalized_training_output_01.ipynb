{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all Normalized Training Tests\n",
    "- ## We've run random architecture on the normalized data\n",
    "- ## We've run \"decreasing nodes only\" on the normalized data\n",
    "- ## We've run \"increasing nodes only\" on the normalized data\n",
    "\n",
    "Get rid of the question if node +/- per layer is somewhet important  \n",
    "In all cases, we've also limited epochs to 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=4>Slight correction that in the decrasing onyl and increasing only designs, since the size of the next layer is based on the fixed size of the first layer, then technically, they only decrease/increase once. Should we fix that?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other day we ran the MLP on our normalized data.  \n",
    "We can check now to see which network architecture did best.  \n",
    "We used much smaller networks, since we realied that youcoud get good results just by using a lot of epochs. This boring, but this is exactly hwat ANNs are supposed to do. There's no goo ay to check if this wa sovefitting, and there's not time. We can graph that later.\n",
    "\n",
    "For now, let's see what structure won, using the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Random sizing, normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_output_text = open(\"normd_MLP_results.txt\",'r')\n",
    "read_output_text = the_output_text.read()\n",
    "the_output_text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3804063\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(read_output_text))\n",
    "rezsplit_a = read_output_text.split(\"\\n\")\n",
    "print(len(rezsplit_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Last time is just an empty new line. We remove it\n",
    "print(rezsplit_a[36])\n",
    "rezsplit_a.remove('')\n",
    "print(len(rezsplit_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "result_dict_list = [eval(rez) for rez in rezsplit_a]\n",
    "print(len(result_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epochs', 'config', 'result'])\n",
      "{'layers': 1, 'layer': {1: 32}}\n",
      "0.00018095967303458202\n",
      "0.00019810913922975958\n"
     ]
    }
   ],
   "source": [
    "print(result_dict_list[0].keys())\n",
    "print(result_dict_list[0][\"config\"])\n",
    "print(min(result_dict_list[0][\"result\"][\"loss\"]))\n",
    "print(result_dict_list[0][\"result\"][\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since overtraiing can be an issue, it's better to get the last MSE loss value, instead of the minimum MSE loss value, per networl trained. This last value represents the minimized loss after all epochs, and thus, is subject to overfitting. The winner of all the trained networks would have exhibited the least overfitting (forces MSE up) but also have the lowest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'config': {'layers': 1, 'layer': {1: 32}}, 'last_loss': 0.00019810913922975958}\n"
     ]
    }
   ],
   "source": [
    "MSE_loss_results = [{\"epochs\": item['epochs'],\n",
    "                    \"config\":item[\"config\"],\n",
    "                    \"last_loss\": item[\"result\"][\"loss\"][-1]} for item in result_dict_list]\n",
    "print(MSE_loss_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0.0001037829471429312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00019810913922975958,\n",
       " 0.0002125235974270752,\n",
       " 0.0001789974654823382,\n",
       " 0.00020397718994464824,\n",
       " 0.00016098024538547574]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_last_loss = [d[\"last_loss\"] for d in MSE_loss_results]\n",
    "print(len(ALL_last_loss))\n",
    "print(min(ALL_last_loss))\n",
    "ALL_last_loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001037829471429312,\n",
       " 0.00010380897874230821,\n",
       " 0.00011645267039795619,\n",
       " 0.00012146604993525068,\n",
       " 0.00012337757427135495,\n",
       " 0.00012928348986209883,\n",
       " 0.00013121674400170275,\n",
       " 0.0001318091661580946,\n",
       " 0.00013705129824884593,\n",
       " 0.00013785371160182316]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_losses = ALL_last_loss.copy()\n",
    "sorted_losses.sort()\n",
    "sorted_losses[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have the 10 lowest MSE losses amongst the __36__ trained networks.  \n",
    "What we will do now, if go back and find the epochs used to train these networks, and their associated architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epochs': 1000,\n",
       "  'config': {'layers': 3, 'layer': {1: 32, 2: 32, 3: 40}},\n",
       "  'last_loss': 0.00013705129824884593},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 2, 'layer': {1: 64, 2: 64}},\n",
       "  'last_loss': 0.00013785371160182316},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 3, 'layer': {1: 64, 2: 80, 3: 64}},\n",
       "  'last_loss': 0.00012337757427135495},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 3, 'layer': {1: 128, 2: 96, 3: 96}},\n",
       "  'last_loss': 0.00012928348986209883},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 2, 'layer': {1: 32, 2: 32}},\n",
       "  'last_loss': 0.00013121674400170275},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 2, 'layer': {1: 64, 2: 48}},\n",
       "  'last_loss': 0.00011645267039795619},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 2, 'layer': {1: 128, 2: 96}},\n",
       "  'last_loss': 0.0001318091661580946},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 3, 'layer': {1: 32, 2: 40, 3: 24}},\n",
       "  'last_loss': 0.00010380897874230821},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 3, 'layer': {1: 64, 2: 80, 3: 64}},\n",
       "  'last_loss': 0.0001037829471429312},\n",
       " {'epochs': 5000,\n",
       "  'config': {'layers': 3, 'layer': {1: 128, 2: 128, 3: 128}},\n",
       "  'last_loss': 0.00012146604993525068}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_losses = sorted_losses[:10]\n",
    "top_ten_networks = [ntwk for ntwk in MSE_loss_results if ntwk[\"last_loss\"] in top_ten_losses]\n",
    "top_ten_networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WInner - Randomized size, Normalized Data\n",
    "`{'epochs': 5000,\n",
    "  'config': {'layers': 3, 'layer': {1: 64, 2: 80, 3: 64}},\n",
    "  'last_loss': 0.0001037829471429312}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1888039188310753"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00012337757427135495/0.0001037829471429312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning network used 5000 epochs. The best 2500 netowrk had an MSE 18% higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # (Once) Decreasing size, Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_output_text = open(\"normd_MLP_decreaseOnly_results.txt\",'r')\n",
    "read_output_text = dec_output_text.read()\n",
    "dec_output_text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256147\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(read_output_text))\n",
    "rezsplit_b = read_output_text.split(\"\\n\")\n",
    "print(len(rezsplit_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Last time is just an empty new line. We remove it\n",
    "print(rezsplit_b[36].__repr__())\n",
    "rezsplit_b.remove('')\n",
    "print(len(rezsplit_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "dec_result_dict_list = [eval(rez) for rez in rezsplit_b]\n",
    "print(len(dec_result_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epochs', 'config', 'result'])\n",
      "{'layers': 1, 'layer': {1: 32}}\n",
      "0.00019301032129192584\n",
      "0.00019513249485453792\n"
     ]
    }
   ],
   "source": [
    "print(dec_result_dict_list[0].keys())\n",
    "print(dec_result_dict_list[0][\"config\"])\n",
    "print(min(dec_result_dict_list[0][\"result\"][\"loss\"]))\n",
    "print(dec_result_dict_list[0][\"result\"][\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since overtraiing can be an issue, it's better to get the last MSE loss value, instead of the minimum MSE loss value, per networl trained. This last value represents the minimized loss after all epochs, and thus, is subject to overfitting. The winner of all the trained networks would have exhibited the least overfitting (forces MSE up) but also have the lowest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'config': {'layers': 1, 'layer': {1: 32}}, 'last_loss': 0.00019513249485453792}\n"
     ]
    }
   ],
   "source": [
    "dec_MSE_loss_results = [{\"epochs\": item['epochs'],\n",
    "                    \"config\":item[\"config\"],\n",
    "                    \"last_loss\": item[\"result\"][\"loss\"][-1]} for item in dec_result_dict_list]\n",
    "print(dec_MSE_loss_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0.00011814708087924505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00019513249485453792,\n",
       " 0.00019331175470670912,\n",
       " 0.00017789038901784758,\n",
       " 0.000190075967591886,\n",
       " 0.0001672903911852994]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_dec_last_loss = [d[\"last_loss\"] for d in dec_MSE_loss_results]\n",
    "print(len(ALL_dec_last_loss))\n",
    "print(min(ALL_dec_last_loss))\n",
    "ALL_dec_last_loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00011814708087924505,\n",
       " 0.00011960595125111938,\n",
       " 0.00012662203209443947,\n",
       " 0.0001267389475122838,\n",
       " 0.00013020875631860785,\n",
       " 0.00013740812264046272,\n",
       " 0.00013758901139934894,\n",
       " 0.0001425576340240002,\n",
       " 0.0001447781587708065,\n",
       " 0.00014656314476686698]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_declosses = ALL_dec_last_loss.copy()\n",
    "sorted_declosses.sort()\n",
    "sorted_declosses[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have the 10 lowest MSE losses amongst the __36__ trained networks.  \n",
    "What we will do now, if go back and find the epochs used to train these networks, and their associated architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epochs': 1000,\n",
       "  'config': {'layers': 3, 'layer': {1: 32, 2: 24, 3: 24}},\n",
       "  'last_loss': 0.00014656314476686698},\n",
       " {'epochs': 1000,\n",
       "  'config': {'layers': 4, 'layer': {1: 32, 2: 24, 3: 24, 4: 24}},\n",
       "  'last_loss': 0.0001447781587708065},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 2, 'layer': {1: 32, 2: 24}},\n",
       "  'last_loss': 0.0001425576340240002},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 2, 'layer': {1: 64, 2: 48}},\n",
       "  'last_loss': 0.00013020875631860785},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 2, 'layer': {1: 128, 2: 96}},\n",
       "  'last_loss': 0.00012662203209443947},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 3, 'layer': {1: 32, 2: 24, 3: 24}},\n",
       "  'last_loss': 0.0001267389475122838},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 3, 'layer': {1: 64, 2: 48, 3: 48}},\n",
       "  'last_loss': 0.00013740812264046272},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 4, 'layer': {1: 32, 2: 24, 3: 24, 4: 24}},\n",
       "  'last_loss': 0.00013758901139934894},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 4, 'layer': {1: 64, 2: 48, 3: 48, 4: 48}},\n",
       "  'last_loss': 0.00011814708087924505},\n",
       " {'epochs': 2500,\n",
       "  'config': {'layers': 4, 'layer': {1: 128, 2: 96, 3: 96, 4: 96}},\n",
       "  'last_loss': 0.00011960595125111938}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_top_ten_losses = sorted_declosses[:10]\n",
    "dec_top_ten_networks = [ntwk for ntwk in dec_MSE_loss_results if ntwk[\"last_loss\"] in dec_top_ten_losses]\n",
    "dec_top_ten_networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner, decreasing only, normalized data\n",
    "`{'epochs': 2500,\n",
    "  'config': {'layers': 4, 'layer': {1: 64, 2: 48, 3: 48, 4: 48}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # (Once) Increasing size, Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
